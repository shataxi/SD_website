[
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blogs",
    "section": "",
    "text": "Mean Average Precision\n\n\n\n\n\n\nobject detection\n\n\nMAP\n\n\n\nAn important metric in Object detection tasks\n\n\n\n\n\nMay 23, 2024\n\n\nShataxi Dubey\n\n\n\n\n\n\n\n\n\n\n\n\nPython Format Specifier\n\n\n\n\n\n\nprecision\n\n\nformat\n\n\n\nFormatting numbers\n\n\n\n\n\nMay 9, 2024\n\n\nShataxi Dubey\n\n\n\n\n\n\n\n\n\n\n\n\nImage Transformation\n\n\n\n\n\n\nimages\n\n\nopencv\n\n\n\nVarious ways to transform image\n\n\n\n\n\nDec 24, 2023\n\n\nShataxi Dubey\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Image-transformation.html",
    "href": "posts/Image-transformation.html",
    "title": "Image Transformation",
    "section": "",
    "text": "import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/Image-transformation.html#reading-image",
    "href": "posts/Image-transformation.html#reading-image",
    "title": "Image Transformation",
    "section": "Reading Image",
    "text": "Reading Image\n\n# read the input image\nimg = cv2.imread(\"../images/trees.jpg\")\n# convert from BGR to RGB so we can plot using matplotlib\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n# disable x & y axis\nplt.axis('off')\n# show the image\nplt.imshow(img)\nplt.show()"
  },
  {
    "objectID": "posts/Image-transformation.html#translation-of-image",
    "href": "posts/Image-transformation.html#translation-of-image",
    "title": "Image Transformation",
    "section": "Translation of image",
    "text": "Translation of image\n\n# get the image shape\nprint(img.shape)\nrows, cols, dim = img.shape\n# transformation matrix for translation\nM = np.float32([[1, 0, 500],\n                [0, 1, 500],\n                [0, 0, 1]])\n# apply a perspective transformation to the image\ntranslated_img = cv2.warpPerspective(img, M, (cols, rows))\n# disable x & y axis\nplt.axis('off')\n# show the resulting image\nplt.imshow(translated_img)\nplt.show()\n\n(1606, 2222, 3)"
  },
  {
    "objectID": "posts/Image-transformation.html#scaling-of-image",
    "href": "posts/Image-transformation.html#scaling-of-image",
    "title": "Image Transformation",
    "section": "Scaling of Image",
    "text": "Scaling of Image\n\n# get the image shape\nprint(img.shape)\nrows, cols, dim = img.shape\n#transformation matrix for Scaling\nM = np.float32([[1.5, 0  , 0],\n                [0,   1.8, 0],\n                [0,   0,   1]])\n# apply a perspective transformation to the image\nscaled_img = cv2.warpPerspective(img,M,(cols,rows))\n# disable x & y axis\nplt.axis('off')\n# show the resulting image\nplt.imshow(scaled_img)\nplt.show()\n\n(1606, 2222, 3)"
  },
  {
    "objectID": "posts/Image-transformation.html#shearing-of-image",
    "href": "posts/Image-transformation.html#shearing-of-image",
    "title": "Image Transformation",
    "section": "Shearing of Image",
    "text": "Shearing of Image\n\n# get the image shape\nprint(img.shape)\nrows, cols, dim = img.shape\n# transformation matrix for Shearing\n# shearing applied to x-axis\nM = np.float32([[1, 0.5, 0],\n                [0, 1  , 0],\n                [0, 0  , 1]])\n# shearing applied to y-axis\n# M = np.float32([[1,   0, 0],\n#                 [0.5, 1, 0],\n#                 [0,   0, 1]])\n# apply a perspective transformation to the image                \nsheared_img = cv2.warpPerspective(img,M,(cols,rows))\n# disable x & y axis\nplt.axis('off')\n# show the resulting image\nplt.imshow(sheared_img)\nplt.show()\n\n(1606, 2222, 3)"
  },
  {
    "objectID": "posts/Image-transformation.html#reflection-of-image",
    "href": "posts/Image-transformation.html#reflection-of-image",
    "title": "Image Transformation",
    "section": "Reflection of Image",
    "text": "Reflection of Image\n\n# get the image shape\nrows, cols, dim = img.shape\n# transformation matrix for x-axis reflection \nM1 = np.float32([[1,  0, 0   ],\n                [0, -1, rows],\n                [0,  0, 1   ]])\n# transformation matrix for y-axis reflection\nM2 = np.float32([[-1, 0, cols],\n                [ 0, 1, 0   ],\n                [ 0, 0, 1   ]])\n# apply a perspective transformation to the image\nh_reflected_img = cv2.warpPerspective(img,M1,(cols,rows))\nv_reflected_img = cv2.warpPerspective(img,M2,(cols,rows))\n# disable x & y axis\nplt.axis('off')\n# show the resulting image\ncombined=np.hstack((h_reflected_img,v_reflected_img))\n\nplt.title('X-axis reflection and Y-axis reflection')\nplt.imshow(combined)\nplt.show()"
  },
  {
    "objectID": "posts/Image-transformation.html#rotation-of-image",
    "href": "posts/Image-transformation.html#rotation-of-image",
    "title": "Image Transformation",
    "section": "Rotation of Image",
    "text": "Rotation of Image\n\n# get the image shape\nrows, cols, dim = img.shape\n#angle from degree to radian\nangle = np.radians(10)\n#transformation matrix for Rotation\nM = np.float32([[np.cos(angle), -(np.sin(angle)), 0],\n                [np.sin(angle), np.cos(angle), 0],\n                [0, 0, 1]])\n# apply a perspective transformation to the image\nrotated_img = cv2.warpPerspective(img, M, (int(cols),int(rows)))\n# disable x & y axis\nplt.axis('off')\n# show the resulting image\nplt.imshow(rotated_img)\nplt.show()"
  },
  {
    "objectID": "posts/Image-transformation.html#cropping-of-image",
    "href": "posts/Image-transformation.html#cropping-of-image",
    "title": "Image Transformation",
    "section": "Cropping of Image",
    "text": "Cropping of Image\n\n# get 200 pixels from 100 to 300 on both x-axis & y-axis\n# change that if you will, just make sure you don't exceed cols & rows\ncropped_img = img[100:300, 100:300]\n# disable x & y axis\nplt.axis('off')\n# show the resulting image\nplt.imshow(cropped_img)\nplt.show()"
  },
  {
    "objectID": "posts/Image-transformation.html#center-crop-of-image",
    "href": "posts/Image-transformation.html#center-crop-of-image",
    "title": "Image Transformation",
    "section": "Center Crop of Image",
    "text": "Center Crop of Image\n\n# get the image width & height\nwidth, height = img.shape[1], img.shape[0]\n\n# get the image cropped width & height\ncrop_width , crop_height = 500, 600\n\nhalf_crop_width , half_crop_height = int(crop_width/2) , int(crop_height/2)\n\nmid_x, mid_y = int(width/2), int(height/2)\n\ncenter_cropped_img=img[mid_y-half_crop_height : mid_y+half_crop_height, mid_x-half_crop_width : mid_x+half_crop_width]\n\n# disable x & y axis\nplt.axis('off')\n# show the resulting image\nplt.imshow(center_cropped_img)\nplt.show()"
  },
  {
    "objectID": "posts/SOTA_object_detection.html",
    "href": "posts/SOTA_object_detection.html",
    "title": "Shataxi Dubey",
    "section": "",
    "text": "two stage detector –&gt; one stage detector –&gt; anchor free"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shataxi Dubey",
    "section": "",
    "text": "Hi! I am Shataxi Dubey an M.Tech Computer Science & Engineering student at Indian Institute of Technology Gandhinagar.\nMy interest area lies on the intersection of Mathematics & Computer Science. It gives the power to unveil the hidden patterns and facts. I will be working on my thesis under the guidance of Prof. Nipun Batra this Spring.\nHoping to add sustainable solutions to make world better!"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Shataxi Dubey",
    "section": "Education",
    "text": "Education\nB.Tech Computer Science and Engineering | University of Allahabad | Prayagraj, Uttar Pradesh | July 2018 - May 2022"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Shataxi Dubey",
    "section": "Experience",
    "text": "Experience\nAssociate Engineer | Indiamart Intermesh Ltd | May 2022 - July 2023"
  },
  {
    "objectID": "posts/python-format-specifier.html",
    "href": "posts/python-format-specifier.html",
    "title": "Python Format Specifier",
    "section": "",
    "text": "To format a number to sum precision point using format\n\n'{:.3f}'.format(3.145667)\n\n'3.146'\n\n\n\n'{:.3f}'.format(3.1)\n\n'3.100'"
  },
  {
    "objectID": "posts/mean_average_precision.html",
    "href": "posts/mean_average_precision.html",
    "title": "Mean Average Precision",
    "section": "",
    "text": "https://youtu.be/FppOzcDvaDI?si=Dwv7FEAoaS9CLlGH\nIt is a graph between precision and recall for different confidence score with a paricular IOU. The precision recall curve will be different for different IOUs.\nThe area under the Precision-Recall curve is the average precision. Higher the area under curve, higher the average precision.\nAverage Precision(AP) is calculated for each class.\nMean Average Precision is calculated by taking average of the AP of two classes.\nSuppose we have two classes : Dogs and Cats\nNow, we will calculate the Precision-Recall curve for dog class. Suppose there are two images of dog in which\nthe number of ground truth boxes are : 4 the number of predicted boxes are : 2\nFor first image :\nthe number of ground truth boxes are : 1 the number of predicted boxes are : 2\nFor Second image :\nthe number of ground truth boxes are : 3 the number of predicted boxes are : 2\nSo we will start from first image with its first predicted bounding box.\nWe will check:\n\nis the predicted box has IOU greater than threshold –&gt; If yes then the predicted box is true positive\nIf No then predicted box is false positive.\n\nSuppose the first predicted box has IOU greater than threshold then\nPrecision till now : 1 divided by total predicted boxes till now which is equal to 1 , so precision is 1\nRecall till now: 1 divided by total number of ground truth boxes which is equal to 4, so recall is 0.25\nNow come to second predicted box of first image.\nSuppose the second predicted box has IOU less than threshold then\nPrecision till now : 1 divided by total predicted boxes till now which is equal to 2 , so precision is 0.5\nRecall till now: 1 divided by total number of ground truth boxes which is equal to 4, so recall is 0.25\nNext, we will go to second image.\nSuppose the first predicted box has IOU greater than threshold then\nPrecision till now : 2 divided by total predicted boxes till now which is equal to 3 , so precision is 0.66 (Why true positives are 2 because we have total correctly predicted boxes till now equal to 2)\nRecall till now: 2 divided by total number of ground truth boxes which is equal to 4, so recall is 0.5\nNow come to second predicted box of second image.\nSuppose the second predicted box has IOU less than threshold then\nPrecision till now : 2 divided by total predicted boxes till now which is equal to 4 , so precision is 0.5\nRecall till now: 2 divided by total number of ground truth boxes which is equal to 4, so recall is 0.5\nNow for plotting the P-R curve, we need all precision values: 1, 0.5, 0.66, 0.5 and all recall values: 0.25, 0.25, 0.5, 0.5\nThis will plot the curve for a particular IOU threshold. Now calculate the area under the curve, which will give the average precision at a particular threshold for Dog class.\nSimilarly, we can do for Cat class and can get the average precision.\nTo get the ean average precision, we take the average of the Average precision of the two classes."
  }
]